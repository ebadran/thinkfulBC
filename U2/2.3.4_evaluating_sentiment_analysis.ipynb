{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Sentiment analysis\n",
    "\n",
    "**U2 L3 P4 - Emile Badran**\n",
    "\n",
    "Perform a sentiment analysis, classifying whether feedback left on a website is either positive or negative.\n",
    "\n",
    "The [dataset of sentiment labelled sentences](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences) that is used here was created for the paper [From Group to Individual Labels using Deep Features, Kotzias et. al., KDD 2015](http://mdenil.com/media/papers/2015-deep-multi-instance-learning.pdf).\n",
    "\n",
    "To increase sentiment analysis precision, a lexicon with 6687 positive and negative words from the University of Illinois at Chicago's College of Engineering was used. The lexicon files [are available online](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) and were created for the papers:\n",
    "\n",
    ">   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
    ">       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
    ">       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
    ">       Washington, USA, \n",
    "\n",
    ">   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \n",
    ">       and Comparing Opinions on the Web.\" Proceedings of the 14th \n",
    ">       International World Wide Web conference (WWW-2005), May 10-14, \n",
    ">       2005, Chiba, Japan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very very very slowmoving aimless movie about a distressed drifting young man</td>\n",
       "      <td>{drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure who was more lost  the flat characters or the audience nearly half of whom walked out</td>\n",
       "      <td>{lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempting artiness with black  white and clever camera angles the movie disappointed  became even more ridiculous  as the acting was poor and the plot and lines almost nonexistent</td>\n",
       "      <td>{camera, almost, poor, angles, nonexistent, was, disappointed, ridiculous, acting, and, as, lines, movie, the, even, with, artiness, attempting, plot, clever, more, became, white, black}</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                   review  \\\n",
       "0  a very very very slowmoving aimless movie about a distressed drifting young man                                                                                                          \n",
       "1  not sure who was more lost  the flat characters or the audience nearly half of whom walked out                                                                                           \n",
       "2  attempting artiness with black  white and clever camera angles the movie disappointed  became even more ridiculous  as the acting was poor and the plot and lines almost nonexistent     \n",
       "\n",
       "                                                                                                                                                                                         sets  \\\n",
       "0  {drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}                                                                                                               \n",
       "1  {lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}                                                                                  \n",
       "2  {camera, almost, poor, angles, nonexistent, was, disappointed, ridiculous, acting, and, as, lines, movie, the, even, with, artiness, attempting, plot, clever, more, became, white, black}   \n",
       "\n",
       "   target  \n",
       "0  False   \n",
       "1  False   \n",
       "2  False   "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load positive lexicon with utf-8 encoding:\n",
    "f = codecs.open('sentiment_labelled/positive-words.txt', encoding='utf-8')\n",
    "positive_vocab = f.read().splitlines()\n",
    "\n",
    "# load negative lexicon with utf-8 encoding:\n",
    "g = codecs.open('sentiment_labelled/negative-words.txt', encoding='utf-8')\n",
    "negative_vocab = g.read().splitlines()\n",
    "\n",
    "# Read the imdb sentiment labelled data set:\n",
    "df = pd.read_table('sentiment_labelled/imdb_labelled.txt', encoding='UTF-8', header=None, quoting=3)\n",
    "df.columns = ['review','target']\n",
    "\n",
    "# Score is either 1 (for positive) or 0 (for negative).\n",
    "# Convert the target column values to boolean objects:\n",
    "df['target'] = (df['target'] == 1)\n",
    "\n",
    "# Convert all words in the reviews column to lower case:\n",
    "df.review = df.review.str.lower()\n",
    "\n",
    "# declare a function that will strip all punctuation marks from reviews:\n",
    "def f_punct(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)\n",
    "\n",
    "# strip all puctuation marks:\n",
    "df['review'] = df['review'].apply(lambda x: f_punct(x))\n",
    "\n",
    "# declare a function that will create a column with the set of words from each review:\n",
    "def f_set(string):\n",
    "    set(string.split())\n",
    "\n",
    "# generate sets from reviews:\n",
    "df['sets'] = df['review'].apply(lambda x: set(x.split()))\n",
    "\n",
    "# reorder dataframe columns:\n",
    "df = df[['review', 'sets', 'target']]\n",
    "\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the column generation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sets</th>\n",
       "      <th>very</th>\n",
       "      <th>drifting</th>\n",
       "      <th>lost</th>\n",
       "      <th>whom</th>\n",
       "      <th>camera</th>\n",
       "      <th>ridiculous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{camera, almost, poor, angles, nonexistent, was, disappointed, ridiculous, acting, and, as, lines, movie, the, even, with, artiness, attempting, plot, clever, more, became, white, black}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                         sets  \\\n",
       "0  {drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}                                                                                                               \n",
       "1  {lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}                                                                                  \n",
       "2  {camera, almost, poor, angles, nonexistent, was, disappointed, ridiculous, acting, and, as, lines, movie, the, even, with, artiness, attempting, plot, clever, more, became, white, black}   \n",
       "\n",
       "   very drifting  lost  whom camera ridiculous  \n",
       "0  True  True     None  None  None   None       \n",
       "1  None  None     True  True  None   None       \n",
       "2  None  None     None  None  True   True       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare a function that returns true when a word is in a set:\n",
    "def in_set(x, word):\n",
    "    for i in x:\n",
    "        if i == word:\n",
    "            return True\n",
    "\n",
    "# create a list of words contained in the first three reviews to easily test the model:\n",
    "words = ['very', 'drifting', 'lost','whom','camera','ridiculous']\n",
    "\n",
    "df_test = df[['sets']]\n",
    "\n",
    "# iterate the \"words\" list to test the model: create a column for every word\n",
    "# in the \"words\" list, then apply the in_set function for every cell in \n",
    "# the \"sets\" column. \n",
    "for word in words:\n",
    "    df_test[word] = df_test['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "df_test.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most common positive and negative words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_positive = df[['sets']]\n",
    "\n",
    "# iterate and create columns for every word in the lexicon;\n",
    "# apply the in_set function to every cell and return true when a word is in the set.\n",
    "for word in positive_vocab:\n",
    "    df_positive[word] = df_positive['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "positive_count = df_positive.iloc[:,1:].sum()\n",
    "positive_count = positive_count.sort_values(ascending=False)\n",
    "top_positive = list(positive_count[:4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_negative = df[['sets']]\n",
    "\n",
    "# iterate and create columns for every word in the lexicon;\n",
    "# apply the in_set function to every cell and return true when a word is in the set.\n",
    "for word in negative_vocab:\n",
    "    df_negative[word] = df_negative['sets'].apply(lambda x: in_set(x, word))\n",
    "    \n",
    "negative_count = df_negative.iloc[:,1:].sum()\n",
    "negative_count = negative_count.sort_values(ascending=False)\n",
    "top_negative = list(negative_count[:6].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove positive or neutral words from the negative list:\n",
    "top_negative.remove('funny')\n",
    "top_negative.remove('plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating the full dataset for training:\n",
    "for word in top_positive:\n",
    "    df[word] = df['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "for word in top_negative:\n",
    "    df[word] = df['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "# fill none (empty) cells with \"False\"\n",
    "df = df.fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The resulting DataFrame has only eight features:\n",
    "\n",
    "The features consist of the top 4 positive words and the top 4 negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sets</th>\n",
       "      <th>target</th>\n",
       "      <th>good</th>\n",
       "      <th>like</th>\n",
       "      <th>great</th>\n",
       "      <th>well</th>\n",
       "      <th>bad</th>\n",
       "      <th>stupid</th>\n",
       "      <th>waste</th>\n",
       "      <th>awful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very very very slowmoving aimless movie about a distressed drifting young man</td>\n",
       "      <td>{drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure who was more lost  the flat characters or the audience nearly half of whom walked out</td>\n",
       "      <td>{lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             review  \\\n",
       "0  a very very very slowmoving aimless movie about a distressed drifting young man                    \n",
       "1  not sure who was more lost  the flat characters or the audience nearly half of whom walked out     \n",
       "\n",
       "                                                                                                          sets  \\\n",
       "0  {drifting, young, slowmoving, about, aimless, distressed, man, very, a, movie}                                \n",
       "1  {lost, the, out, was, flat, nearly, sure, more, walked, characters, who, not, half, of, or, audience, whom}   \n",
       "\n",
       "   target   good   like  great   well    bad  stupid  waste  awful  \n",
       "0  False   False  False  False  False  False  False   False  False  \n",
       "1  False   False  False  False  False  False  False   False  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 0\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe with only the boolean columns, and a variable with the target column:\n",
    "data = df.iloc[:,2:]\n",
    "target = df.target\n",
    "\n",
    "# Instantiate the model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit the model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display the results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on the Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sets</th>\n",
       "      <th>target</th>\n",
       "      <th>good</th>\n",
       "      <th>like</th>\n",
       "      <th>great</th>\n",
       "      <th>well</th>\n",
       "      <th>bad</th>\n",
       "      <th>stupid</th>\n",
       "      <th>waste</th>\n",
       "      <th>awful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>{place, this, loved, wow}</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>{good, crust, not, is}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>{the, was, texture, nasty, tasty, and, just, not}</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review  \\\n",
       "0  wow loved this place                       \n",
       "1  crust is not good                          \n",
       "2  not tasty and the texture was just nasty   \n",
       "\n",
       "                                                sets  target   good   like  \\\n",
       "0  {place, this, loved, wow}                          True    False  False   \n",
       "1  {good, crust, not, is}                             False   True   False   \n",
       "2  {the, was, texture, nasty, tasty, and, just, not}  False   False  False   \n",
       "\n",
       "   great   well    bad  stupid  waste  awful  \n",
       "0  False  False  False  False   False  False  \n",
       "1  False  False  False  False   False  False  \n",
       "2  False  False  False  False   False  False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Yelp sentiment labelled data set:\n",
    "df2 = pd.read_table('sentiment_labelled/yelp_labelled.txt', encoding='UTF-8', header=None, quoting=3)\n",
    "\n",
    "df2.columns = ['review','target']\n",
    "df2['target'] = (df2['target'] == 1)\n",
    "df2.review = df2.review.str.lower()\n",
    "\n",
    "df2['review'] = df2['review'].apply(lambda x: f_punct(x))\n",
    "df2['sets'] = df2['review'].apply(lambda x: set(x.split()))\n",
    "\n",
    "df2 = df2[['review', 'sets', 'target']]\n",
    "\n",
    "for word in top_positive:\n",
    "    df2[word] = df2['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "for word in top_negative:\n",
    "    df2[word] = df2['sets'].apply(lambda x: in_set(x, word))\n",
    "\n",
    "df2 = df2.fillna(False)\n",
    "\n",
    "df2.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 0\n"
     ]
    }
   ],
   "source": [
    "data2 = df2.iloc[:,2:]\n",
    "target2 = df2.target\n",
    "\n",
    "# Instantiate the model and store it in a new variable.\n",
    "bnb2 = BernoulliNB()\n",
    "\n",
    "# Fit the model to the data.\n",
    "bnb2.fit(data2, target2)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred2 = bnb2.predict(data2)\n",
    "\n",
    "# Display the results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data2.shape[0],\n",
    "    (target2 != y_pred2).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix, holdout and cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[500,   0],\n",
       "       [  0, 500]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix of the first data set (IMDB):\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 1.0\n",
      "Testing on Sample: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test the model with different holdout groups with sklearn:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validating with the sklearn:\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized cross-validation methods:\n",
    "### Ten-fold cross-validation (entire data set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 0 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[39  0]\n",
      " [ 0 61]]\n",
      "\n",
      "Round 1 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[79  0]\n",
      " [ 0 21]]\n",
      "\n",
      "Round 2 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[55  0]\n",
      " [ 0 45]]\n",
      "\n",
      "Round 3 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[40  0]\n",
      " [ 0 60]]\n",
      "\n",
      "Round 4 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[56  0]\n",
      " [ 0 44]]\n",
      "\n",
      "Round 5 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[73  0]\n",
      " [ 0 27]]\n",
      "\n",
      "Round 6 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[32  0]\n",
      " [ 0 68]]\n",
      "\n",
      "Round 7 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[40  0]\n",
      " [ 0 60]]\n",
      "\n",
      "Round 8 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[53  0]\n",
      " [ 0 47]]\n",
      "\n",
      "Round 9 \n",
      "accuracy: 1.0 \n",
      "sensitivity: 1.0 \n",
      "specificity: 1.0 \n",
      "confusion mat:\n",
      " [[33  0]\n",
      " [ 0 67]]\n"
     ]
    }
   ],
   "source": [
    "result_df = target.to_frame(name='target')\n",
    "result_df['y_pred'] = y_pred\n",
    "\n",
    "start = 0\n",
    "end = int(len(target)/10)\n",
    "multi = 10\n",
    "\n",
    "for i in range(10):\n",
    "    sample = result_df[start:end]    \n",
    "\n",
    "    t_negatives = len(sample[sample.target == False][sample.y_pred == False])\n",
    "    f_negatives = len(sample[sample.target == True][sample.y_pred == False])\n",
    "    t_positives = len(sample[sample.target == True][sample.y_pred == True])\n",
    "    f_positives = len(sample[sample.target == False][sample.y_pred == True])\n",
    "\n",
    "    acc = (sample.target == sample.y_pred).sum() / len(sample)\n",
    "    sens = (t_positives / (t_positives + f_negatives))\n",
    "    spec = (t_negatives / (t_negatives + f_positives))\n",
    "    \n",
    "\n",
    "    print('\\nRound', i, '\\naccuracy:', acc, '\\nsensitivity:', sens,\n",
    "          '\\nspecificity:',  spec, '\\nconfusion mat:\\n', confusion_matrix(sample.target, sample.y_pred))\n",
    "    \n",
    "    start = end\n",
    "    end = end+(int(len(target)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running/testing the model increasing sample size by 10x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 0 Sample size = 100 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[39  0]\n",
      " [ 0 61]]\n",
      "\n",
      "Round 1 Sample size = 200 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[118   0]\n",
      " [  0  82]]\n",
      "\n",
      "Round 2 Sample size = 300 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[173   0]\n",
      " [  0 127]]\n",
      "\n",
      "Round 3 Sample size = 400 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[213   0]\n",
      " [  0 187]]\n",
      "\n",
      "Round 4 Sample size = 500 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[269   0]\n",
      " [  0 231]]\n",
      "\n",
      "Round 5 Sample size = 600 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[342   0]\n",
      " [  0 258]]\n",
      "\n",
      "Round 6 Sample size = 700 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[374   0]\n",
      " [  0 326]]\n",
      "\n",
      "Round 7 Sample size = 800 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[414   0]\n",
      " [  0 386]]\n",
      "\n",
      "Round 8 Sample size = 900 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[467   0]\n",
      " [  0 433]]\n",
      "\n",
      "Round 9 Sample size = 1000 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[500   0]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "end = int(len(df.target)/10)\n",
    "\n",
    "for i in range(10):\n",
    "        \n",
    "    data = df.iloc[0:end, 2:]\n",
    "    target = df.target[0:end]\n",
    "\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(data, target)\n",
    "    y_pred = bnb.predict(data)\n",
    "\n",
    "    result_df = target.to_frame(name='target')\n",
    "    result_df['y_pred'] = y_pred\n",
    "\n",
    "    t_negatives = len(result_df[result_df.target == False][result_df.y_pred == False])\n",
    "    f_negatives = len(result_df[result_df.target == True][result_df.y_pred == False])\n",
    "    t_positives = len(result_df[result_df.target == True][result_df.y_pred == True])\n",
    "    f_positives = len(result_df[result_df.target == False][result_df.y_pred == True])\n",
    "\n",
    "    acc = (result_df.target == result_df.y_pred).sum() / len(result_df)\n",
    "#    sens = (t_positives / (t_positives + f_negatives))\n",
    "#    spec = (t_negatives / (t_negatives + f_positives))\n",
    "    \n",
    "\n",
    "    print('\\nRound', i, 'Sample size =', len(target), '\\naccuracy:', acc, '\\nconfusion mat:\\n',\n",
    "          confusion_matrix(result_df.target, result_df.y_pred))\n",
    "    \n",
    "    end = end+(int(len(df.target)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running/testing the model with random samples of increasing sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 0 Sample size = 100 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[52  0]\n",
      " [ 0 48]]\n",
      "\n",
      "Round 1 Sample size = 200 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[ 83   0]\n",
      " [  0 117]]\n",
      "\n",
      "Round 2 Sample size = 300 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[148   0]\n",
      " [  0 152]]\n",
      "\n",
      "Round 3 Sample size = 400 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[198   0]\n",
      " [  0 202]]\n",
      "\n",
      "Round 4 Sample size = 500 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[242   0]\n",
      " [  0 258]]\n",
      "\n",
      "Round 5 Sample size = 600 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[295   0]\n",
      " [  0 305]]\n",
      "\n",
      "Round 6 Sample size = 700 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[348   0]\n",
      " [  0 352]]\n",
      "\n",
      "Round 7 Sample size = 800 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[416   0]\n",
      " [  0 384]]\n",
      "\n",
      "Round 8 Sample size = 900 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[446   0]\n",
      " [  0 454]]\n",
      "\n",
      "Round 9 Sample size = 1000 \n",
      "accuracy: 1.0 \n",
      "confusion mat:\n",
      " [[500   0]\n",
      " [  0 500]]\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[0:end, 2:]\n",
    "target = df.target[0:end]\n",
    "\n",
    "sample_size = 100\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    s_data = data.sample(sample_size)\n",
    "    s_target = s_data.target\n",
    "    \n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(s_data, s_target)\n",
    "    y_pred = bnb.predict(s_data)\n",
    "\n",
    "    result_df = s_target.to_frame(name='s_target')\n",
    "    result_df['y_pred'] = y_pred\n",
    "\n",
    "    t_negatives = len(result_df[result_df.s_target == False][result_df.y_pred == False])\n",
    "    f_negatives = len(result_df[result_df.s_target == True][result_df.y_pred == False])\n",
    "    t_positives = len(result_df[result_df.s_target == True][result_df.y_pred == True])\n",
    "    f_positives = len(result_df[result_df.s_target == False][result_df.y_pred == True])\n",
    "\n",
    "    acc = (result_df.s_target == result_df.y_pred).sum() / len(result_df)\n",
    "\n",
    "    print('\\nRound', i, 'Sample size =', len(s_target), '\\naccuracy:', acc, '\\nconfusion mat:\\n',\n",
    "          confusion_matrix(result_df.s_target, result_df.y_pred))\n",
    "    \n",
    "    sample_size += 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
